import streamlit as st
import os
import io
from PIL import Image
from dotenv import load_dotenv
from rag_system import RAGSystem

# Charger les variables d'environnement
load_dotenv()

# Configuration de la page
st.set_page_config(
    page_title="ChatGPT Document Q&A",
    page_icon="üìÑ",
    layout="wide"
)

# Initialiser la cl√© API
api_key = os.getenv("OPENAI_API_KEY")

if not api_key:
    st.error("‚ö†Ô∏è ERREUR: La cl√© API OpenAI n'est pas d√©finie.")
    st.info("""
    Pour d√©finir votre cl√© API :
    1. Cr√©ez un fichier `.env` √† la racine du projet avec :
       `OPENAI_API_KEY=votre-cl√©-api-ici`
    2. Ou d√©finissez une variable d'environnement PowerShell :
       `$env:OPENAI_API_KEY="votre-cl√©-api-ici"`
       """)
    st.stop()

# Importer les fonctions depuis main.py
from main import (
    extract_text,
    count_pages,
    estimate_tokens,
    image_to_base64,
    get_image_mime_type,
    ask_question
)

# Interface Streamlit
st.title("üìÑ ChatGPT Document & Image Q&A")
st.markdown("---")
st.markdown("""
### Comment utiliser cette application :
1. **Uploadez un document** (PDF, DOCX, TXT) **ou une image** (JPG, PNG)
2. Le contenu sera extrait automatiquement
3. **Posez vos questions** sur le document ou l'image
4. ChatGPT r√©pondra en se basant sur le contenu fourni
""")

# Sidebar pour l'upload de fichier et s√©lection du mod√®le
with st.sidebar:
    # S√©lecteur de mod√®le en haut
    st.header("‚öôÔ∏è Configuration")
    
    # Initialiser le mod√®le par d√©faut dans session_state
    if 'selected_model' not in st.session_state:
        st.session_state['selected_model'] = "gpt-3.5-turbo"
    
    # Liste des mod√®les OpenAI disponibles
    available_models = [
        "gpt-3.5-turbo",
        "gpt-4",
        "gpt-4o",
        "gpt-4o-mini"
    ]
    
    # S√©lecteur de mod√®le
    selected_model = st.selectbox(
        "Mod√®le ChatGPT",
        options=available_models,
        index=available_models.index(st.session_state['selected_model']) if st.session_state['selected_model'] in available_models else 0,
        help="S√©lectionnez le mod√®le OpenAI √† utiliser pour les r√©ponses"
    )
    
    # Mettre √† jour le mod√®le dans session_state
    st.session_state['selected_model'] = selected_model
    
    st.markdown("---")
    
    st.header("üì§ Upload Fichier")
    
    # S√©lecteur de type de fichier
    file_type_choice = st.radio(
        "Type de fichier",
        options=["Document", "Image"],
        help="Choisissez si vous voulez uploader un document ou une image"
    )
    
    if file_type_choice == "Document":
        uploaded_file = st.file_uploader(
            "Choisissez un document",
            type=['pdf', 'docx', 'txt'],
            help="Formats support√©s: PDF, DOCX, TXT",
            key="document_uploader"
        )
        uploaded_image = None
    else:
        uploaded_image = st.file_uploader(
            "Choisissez une image",
            type=['jpg', 'jpeg', 'png'],
            help="Formats support√©s: JPG, JPEG, PNG",
            key="image_uploader"
        )
        uploaded_file = None
    
    if uploaded_file is not None:
        st.success(f"‚úÖ Document upload√©: {uploaded_file.name}")
        st.info(f"Taille: {uploaded_file.size} bytes")
        st.info(f"Type: {uploaded_file.type}")
    
    if uploaded_image is not None:
        st.success(f"‚úÖ Image upload√©e: {uploaded_image.name}")
        st.info(f"Taille: {uploaded_image.size} bytes")
        # Afficher un aper√ßu de l'image
        image = Image.open(uploaded_image)
        st.image(image, caption=uploaded_image.name, use_container_width=True)

# Zone principale
if uploaded_file is not None or uploaded_image is not None:
    # G√©rer les documents
    if uploaded_file is not None:
        # Extraire le texte du document
        if 'document_text' not in st.session_state or st.session_state.get('current_file') != uploaded_file.name:
            with st.spinner("Extraction du contenu du document..."):
                file_bytes = uploaded_file.read()
                file_io = io.BytesIO(file_bytes)
                try:
                    # Compter le nombre de pages
                    file_io.seek(0)
                    num_pages = count_pages(file_io, uploaded_file.type)
                    
                    # Extraire le texte avec callback de progression pour les PDFs
                    file_io.seek(0)
                    
                    # Afficher la progression uniquement pour les PDFs (qui peuvent contenir des images)
                    if uploaded_file.type == "application/pdf":
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        def update_progress(page_num, total_pages, message):
                            progress_bar.progress(page_num / total_pages)
                            status_text.text(message)
                        
                        document_text = extract_text(file_io, uploaded_file.type, progress_callback=update_progress)
                        
                        progress_bar.empty()
                        status_text.empty()
                    else:
                        document_text = extract_text(file_io, uploaded_file.type)
                    
                    if document_text:
                        st.session_state['document_text'] = document_text
                        st.session_state['current_file'] = uploaded_file.name
                        st.session_state['current_image'] = None  # R√©initialiser l'image
                        st.session_state['num_pages'] = num_pages
                        
                        # Estimer le nombre de tokens
                        num_tokens = estimate_tokens(document_text)
                        st.session_state['num_tokens'] = num_tokens
                        
                        # D√©terminer automatiquement si on utilise RAG (>= 10 000 tokens)
                        use_rag = num_tokens >= 10000
                        st.session_state['use_rag'] = use_rag
                        
                        if use_rag:
                            with st.spinner("üîç Construction de l'index RAG (cela peut prendre quelques secondes)..."):
                                try:
                                    rag_system = RAGSystem(api_key)
                                    rag_system.build_index(document_text)
                                    st.session_state['rag_system'] = rag_system
                                    st.success(f"‚úÖ Index RAG cr√©√© avec {len(rag_system.chunks)} chunks! (Document: ~{num_tokens:,} tokens)")
                                except Exception as e:
                                    st.warning(f"‚ö†Ô∏è Erreur lors de la cr√©ation de l'index RAG: {str(e)}. Le mode sans RAG sera utilis√©.")
                                    st.session_state['rag_system'] = None
                                    st.session_state['use_rag'] = False
                        else:
                            st.session_state['rag_system'] = None
                            st.info(f"‚ÑπÔ∏è Document de ~{num_tokens:,} tokens : RAG d√©sactiv√© (seuil: 10 000 tokens)")
                        
                        st.success("‚úÖ Contenu extrait avec succ√®s!")
                    else:
                        st.error("‚ùå Impossible d'extraire le contenu du document.")
                        st.stop()
                except Exception as e:
                    st.error(f"‚ùå Erreur lors de l'extraction: {str(e)}")
                    st.stop()
        
        # Afficher un aper√ßu du document
        with st.expander("üìñ Aper√ßu du document (premiers 500 caract√®res)"):
            preview_text = st.session_state['document_text'][:500]
            st.text(preview_text)
            if len(st.session_state['document_text']) > 500:
                st.caption(f"... ({len(st.session_state['document_text']) - 500} caract√®res suppl√©mentaires)")
            
            # Afficher les infos RAG
            num_tokens = st.session_state.get('num_tokens', 0)
            if st.session_state.get('use_rag', False) and hasattr(st.session_state, 'rag_system') and st.session_state.get('rag_system'):
                rag_system = st.session_state['rag_system']
                st.info(f"üîç RAG activ√© automatiquement (~{num_tokens:,} tokens ‚â• 10 000) : {len(rag_system.chunks)} chunks cr√©√©s pour la recherche s√©mantique")
            else:
                st.info(f"‚ÑπÔ∏è RAG d√©sactiv√© (~{num_tokens:,} tokens < 10 000) : tout le document sera envoy√© √† ChatGPT")
    
    # G√©rer les images
    if uploaded_image is not None:
        # Convertir l'image en base64
        if 'current_image' not in st.session_state or st.session_state.get('current_image_name') != uploaded_image.name:
            with st.spinner("Traitement de l'image..."):
                uploaded_image.seek(0)  # R√©initialiser la position
                try:
                    image_base64 = image_to_base64(uploaded_image)
                    image_mime_type = get_image_mime_type(uploaded_image)
                    
                    if image_base64:
                        st.session_state['current_image'] = image_base64
                        st.session_state['current_image_mime'] = image_mime_type
                        st.session_state['current_image_name'] = uploaded_image.name
                        st.session_state['document_text'] = None  # R√©initialiser le texte
                        st.session_state['current_file'] = None  # R√©initialiser le fichier
                        st.success("‚úÖ Image pr√™te pour l'analyse!")
                    else:
                        st.error("‚ùå Impossible de traiter l'image.")
                        st.stop()
                except Exception as e:
                    st.error(f"‚ùå Erreur lors du traitement de l'image: {str(e)}")
                    st.stop()
        
        # Afficher l'image
        st.subheader(" Image √† analyser")
        uploaded_image.seek(0)
        image = Image.open(uploaded_image)
        st.image(image, caption=uploaded_image.name, use_container_width=True)
    
    st.markdown("---")
    
    # Zone de questions
    st.header("üí¨ Posez vos questions")
    
    # Historique des questions/r√©ponses
    if 'chat_history' not in st.session_state:
        st.session_state['chat_history'] = []
    
    # Afficher l'historique
    if st.session_state['chat_history']:
        st.subheader("Historique des questions")
        for i, item in enumerate(st.session_state['chat_history']):
            with st.container():
                # G√©rer l'ancien format (sans mod√®le) et le nouveau format (avec mod√®le)
                if len(item) == 3:
                    q, a, model = item
                    st.markdown(f"**Question {i+1}:** {q}")
                    st.caption(f"Mod√®le utilis√©: {model}")
                    st.markdown(f"**R√©ponse:** {a}")
                else:
                    q, a = item
                    st.markdown(f"**Question {i+1}:** {q}")
                    st.markdown(f"**R√©ponse:** {a}")
                st.markdown("---")
    
    # Formulaire pour poser une question
    with st.form("question_form", clear_on_submit=True):
        question = st.text_area(
            "Votre question:",
            placeholder="Ex: Quel est le sujet principal de ce document?",
            height=100
        )
        submit_button = st.form_submit_button("üîç Poser la question", use_container_width=True)
        
        if submit_button and question:
            # D√©terminer si on analyse un document ou une image
            document_text = st.session_state.get('document_text')
            image_base64 = st.session_state.get('current_image')
            
            if not document_text and not image_base64:
                st.error("‚ùå Aucun contenu disponible. Veuillez uploader un document ou une image.")
            else:
                # Utiliser gpt-4o par d√©faut si une image est pr√©sente
                model = st.session_state['selected_model']
                if image_base64 and model not in ["gpt-4o", "gpt-4-turbo", "gpt-4-vision-preview"]:
                    model = "gpt-4o"
                    st.info("‚ÑπÔ∏è Le mod√®le a √©t√© automatiquement chang√© en gpt-4o pour l'analyse d'images.")
                
                # Afficher l'info RAG si activ√©
                rag_info = ""
                use_rag_flag = st.session_state.get('use_rag', False)
                rag_system = None
                
                if document_text and use_rag_flag and hasattr(st.session_state, 'rag_system') and st.session_state.get('rag_system'):
                    rag_info = " (avec RAG)"
                    rag_system = st.session_state['rag_system']
                
                with st.spinner(f"ü§î ChatGPT ({model}) analyse{rag_info}..."):
                    answer = ask_question(
                        question, 
                        document_text=document_text,
                        image_base64=image_base64,
                        model=model,
                        rag_system=rag_system,
                        use_rag=use_rag_flag
                    )
                    
                    # Ajouter √† l'historique avec le mod√®le utilis√©
                    st.session_state['chat_history'].append((question, answer, st.session_state['selected_model']))
                    
                    # Afficher la r√©ponse
                    st.success("‚úÖ R√©ponse re√ßue!")
                    st.markdown("### R√©ponse:")
                    st.markdown(answer)
                    
                    # Rafra√Æchir pour afficher dans l'historique
                    st.rerun()
    
    # Bouton pour effacer l'historique
    if st.session_state['chat_history']:
        if st.button("üóëÔ∏è Effacer l'historique"):
            st.session_state['chat_history'] = []
            st.rerun()

else:
    st.info("üëà Veuillez uploader un document ou une image dans la barre lat√©rale pour commencer.")

