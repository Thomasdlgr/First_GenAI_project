import streamlit as st
import os
import io
from PIL import Image
from dotenv import load_dotenv
from rag_system import RAGSystem

# Charger les variables d'environnement
load_dotenv()

# Configuration de la page
st.set_page_config(
    page_title="ChatGPT Document Q&A",
    page_icon="ğŸ“„",
    layout="wide"
)

# Initialiser la clÃ© API
api_key = os.getenv("OPENAI_API_KEY")

if not api_key:
    st.error("âš ï¸ ERREUR: La clÃ© API OpenAI n'est pas dÃ©finie.")
    st.info("""
    Pour dÃ©finir votre clÃ© API :
    1. CrÃ©ez un fichier `.env` Ã  la racine du projet avec :
       `OPENAI_API_KEY=votre-clÃ©-api-ici`
    2. Ou dÃ©finissez une variable d'environnement PowerShell :
       `$env:OPENAI_API_KEY="votre-clÃ©-api-ici"`
       """)
    st.stop()

# Importer les fonctions depuis main.py
from main import (
    extract_text,
    count_pages,
    image_to_base64,
    get_image_mime_type,
    ask_question
)

# Interface Streamlit
st.title("ğŸ“„ ChatGPT Document & Image Q&A")
st.markdown("---")
st.markdown("""
### Comment utiliser cette application :
1. **Uploadez un document** (PDF, DOCX, TXT) **ou une image** (JPG, PNG)
2. Le contenu sera extrait automatiquement
3. **Posez vos questions** sur le document ou l'image
4. ChatGPT rÃ©pondra en se basant sur le contenu fourni
""")

# Sidebar pour l'upload de fichier et sÃ©lection du modÃ¨le
with st.sidebar:
    # SÃ©lecteur de modÃ¨le en haut
    st.header("âš™ï¸ Configuration")
    
    # Initialiser le modÃ¨le par dÃ©faut dans session_state
    if 'selected_model' not in st.session_state:
        st.session_state['selected_model'] = "gpt-3.5-turbo"
    
    # Liste des modÃ¨les OpenAI disponibles
    available_models = [
        "gpt-3.5-turbo",
        "gpt-4",
        "gpt-4o",
        "gpt-4o-mini"
    ]
    
    # SÃ©lecteur de modÃ¨le
    selected_model = st.selectbox(
        "ModÃ¨le ChatGPT",
        options=available_models,
        index=available_models.index(st.session_state['selected_model']) if st.session_state['selected_model'] in available_models else 0,
        help="SÃ©lectionnez le modÃ¨le OpenAI Ã  utiliser pour les rÃ©ponses"
    )
    
    # Mettre Ã  jour le modÃ¨le dans session_state
    st.session_state['selected_model'] = selected_model
    
    st.markdown("---")
    
    st.header("ğŸ“¤ Upload Fichier")
    
    # SÃ©lecteur de type de fichier
    file_type_choice = st.radio(
        "Type de fichier",
        options=["Document", "Image"],
        help="Choisissez si vous voulez uploader un document ou une image"
    )
    
    if file_type_choice == "Document":
        uploaded_file = st.file_uploader(
            "Choisissez un document",
            type=['pdf', 'docx', 'txt'],
            help="Formats supportÃ©s: PDF, DOCX, TXT",
            key="document_uploader"
        )
        uploaded_image = None
    else:
        uploaded_image = st.file_uploader(
            "Choisissez une image",
            type=['jpg', 'jpeg', 'png'],
            help="Formats supportÃ©s: JPG, JPEG, PNG",
            key="image_uploader"
        )
        uploaded_file = None
    
    if uploaded_file is not None:
        st.success(f"âœ… Document uploadÃ©: {uploaded_file.name}")
        st.info(f"Taille: {uploaded_file.size} bytes")
        st.info(f"Type: {uploaded_file.type}")
    
    if uploaded_image is not None:
        st.success(f"âœ… Image uploadÃ©e: {uploaded_image.name}")
        st.info(f"Taille: {uploaded_image.size} bytes")
        # Afficher un aperÃ§u de l'image
        image = Image.open(uploaded_image)
        st.image(image, caption=uploaded_image.name, use_container_width=True)

# Zone principale
if uploaded_file is not None or uploaded_image is not None:
    # GÃ©rer les documents
    if uploaded_file is not None:
        # Extraire le texte du document
        if 'document_text' not in st.session_state or st.session_state.get('current_file') != uploaded_file.name:
            with st.spinner("Extraction du contenu du document..."):
                file_bytes = uploaded_file.read()
                file_io = io.BytesIO(file_bytes)
                try:
                    # Compter le nombre de pages
                    file_io.seek(0)
                    num_pages = count_pages(file_io, uploaded_file.type)
                    
                    # Extraire le texte avec callback de progression pour les PDFs
                    file_io.seek(0)
                    
                    # Afficher la progression uniquement pour les PDFs (qui peuvent contenir des images)
                    if uploaded_file.type == "application/pdf":
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        def update_progress(page_num, total_pages, message):
                            progress_bar.progress(page_num / total_pages)
                            status_text.text(message)
                        
                        document_text = extract_text(file_io, uploaded_file.type, progress_callback=update_progress)
                        
                        progress_bar.empty()
                        status_text.empty()
                    else:
                        document_text = extract_text(file_io, uploaded_file.type)
                    
                    if document_text:
                        st.session_state['document_text'] = document_text
                        st.session_state['current_file'] = uploaded_file.name
                        st.session_state['current_image'] = None  # RÃ©initialiser l'image
                        st.session_state['num_pages'] = num_pages
                        
                        # DÃ©terminer automatiquement si on utilise RAG (>= 80 pages)
                        use_rag = num_pages >= 80
                        st.session_state['use_rag'] = use_rag
                        
                        if use_rag:
                            with st.spinner("ğŸ” Construction de l'index RAG (cela peut prendre quelques secondes)..."):
                                try:
                                    rag_system = RAGSystem(api_key)
                                    rag_system.build_index(document_text)
                                    st.session_state['rag_system'] = rag_system
                                    st.success(f"âœ… Index RAG crÃ©Ã© avec {len(rag_system.chunks)} chunks! (Document: {num_pages} pages)")
                                except Exception as e:
                                    st.warning(f"âš ï¸ Erreur lors de la crÃ©ation de l'index RAG: {str(e)}. Le mode sans RAG sera utilisÃ©.")
                                    st.session_state['rag_system'] = None
                                    st.session_state['use_rag'] = False
                        else:
                            st.session_state['rag_system'] = None
                            st.info(f"â„¹ï¸ Document de {num_pages} pages : RAG dÃ©sactivÃ© (seuil: 80 pages)")
                        
                        st.success("âœ… Contenu extrait avec succÃ¨s!")
                    else:
                        st.error("âŒ Impossible d'extraire le contenu du document.")
                        st.stop()
                except Exception as e:
                    st.error(f"âŒ Erreur lors de l'extraction: {str(e)}")
                    st.stop()
        
        # Afficher un aperÃ§u du document
        with st.expander("ğŸ“– AperÃ§u du document (premiers 500 caractÃ¨res)"):
            preview_text = st.session_state['document_text'][:500]
            st.text(preview_text)
            if len(st.session_state['document_text']) > 500:
                st.caption(f"... ({len(st.session_state['document_text']) - 500} caractÃ¨res supplÃ©mentaires)")
            
            # Afficher les infos RAG
            num_pages = st.session_state.get('num_pages', 0)
            if st.session_state.get('use_rag', False) and hasattr(st.session_state, 'rag_system') and st.session_state.get('rag_system'):
                rag_system = st.session_state['rag_system']
                st.info(f"ğŸ” RAG activÃ© automatiquement ({num_pages} pages â‰¥ 80) : {len(rag_system.chunks)} chunks crÃ©Ã©s pour la recherche sÃ©mantique")
            else:
                st.info(f"â„¹ï¸ RAG dÃ©sactivÃ© ({num_pages} pages < 80) : tout le document sera envoyÃ© Ã  ChatGPT")
    
    # GÃ©rer les images
    if uploaded_image is not None:
        # Convertir l'image en base64
        if 'current_image' not in st.session_state or st.session_state.get('current_image_name') != uploaded_image.name:
            with st.spinner("Traitement de l'image..."):
                uploaded_image.seek(0)  # RÃ©initialiser la position
                try:
                    image_base64 = image_to_base64(uploaded_image)
                    image_mime_type = get_image_mime_type(uploaded_image)
                    
                    if image_base64:
                        st.session_state['current_image'] = image_base64
                        st.session_state['current_image_mime'] = image_mime_type
                        st.session_state['current_image_name'] = uploaded_image.name
                        st.session_state['document_text'] = None  # RÃ©initialiser le texte
                        st.session_state['current_file'] = None  # RÃ©initialiser le fichier
                        st.success("âœ… Image prÃªte pour l'analyse!")
                    else:
                        st.error("âŒ Impossible de traiter l'image.")
                        st.stop()
                except Exception as e:
                    st.error(f"âŒ Erreur lors du traitement de l'image: {str(e)}")
                    st.stop()
        
        # Afficher l'image
        st.subheader(" Image Ã  analyser")
        uploaded_image.seek(0)
        image = Image.open(uploaded_image)
        st.image(image, caption=uploaded_image.name, use_container_width=True)
    
    st.markdown("---")
    
    # Zone de questions
    st.header("ğŸ’¬ Posez vos questions")
    
    # Historique des questions/rÃ©ponses
    if 'chat_history' not in st.session_state:
        st.session_state['chat_history'] = []
    
    # Afficher l'historique
    if st.session_state['chat_history']:
        st.subheader("Historique des questions")
        for i, item in enumerate(st.session_state['chat_history']):
            with st.container():
                # GÃ©rer l'ancien format (sans modÃ¨le) et le nouveau format (avec modÃ¨le)
                if len(item) == 3:
                    q, a, model = item
                    st.markdown(f"**Question {i+1}:** {q}")
                    st.caption(f"ModÃ¨le utilisÃ©: {model}")
                    st.markdown(f"**RÃ©ponse:** {a}")
                else:
                    q, a = item
                    st.markdown(f"**Question {i+1}:** {q}")
                    st.markdown(f"**RÃ©ponse:** {a}")
                st.markdown("---")
    
    # Formulaire pour poser une question
    with st.form("question_form", clear_on_submit=True):
        question = st.text_area(
            "Votre question:",
            placeholder="Ex: Quel est le sujet principal de ce document?",
            height=100
        )
        submit_button = st.form_submit_button("ğŸ” Poser la question", use_container_width=True)
        
        if submit_button and question:
            # DÃ©terminer si on analyse un document ou une image
            document_text = st.session_state.get('document_text')
            image_base64 = st.session_state.get('current_image')
            
            if not document_text and not image_base64:
                st.error("âŒ Aucun contenu disponible. Veuillez uploader un document ou une image.")
            else:
                # Utiliser gpt-4o par dÃ©faut si une image est prÃ©sente
                model = st.session_state['selected_model']
                if image_base64 and model not in ["gpt-4o", "gpt-4-turbo", "gpt-4-vision-preview"]:
                    model = "gpt-4o"
                    st.info("â„¹ï¸ Le modÃ¨le a Ã©tÃ© automatiquement changÃ© en gpt-4o pour l'analyse d'images.")
                
                # Afficher l'info RAG si activÃ©
                rag_info = ""
                use_rag_flag = st.session_state.get('use_rag', False)
                rag_system = None
                
                if document_text and use_rag_flag and hasattr(st.session_state, 'rag_system') and st.session_state.get('rag_system'):
                    rag_info = " (avec RAG)"
                    rag_system = st.session_state['rag_system']
                
                with st.spinner(f"ğŸ¤” ChatGPT ({model}) analyse{rag_info}..."):
                    answer = ask_question(
                        question, 
                        document_text=document_text,
                        image_base64=image_base64,
                        model=model,
                        rag_system=rag_system,
                        use_rag=use_rag_flag
                    )
                    
                    # Ajouter Ã  l'historique avec le modÃ¨le utilisÃ©
                    st.session_state['chat_history'].append((question, answer, st.session_state['selected_model']))
                    
                    # Afficher la rÃ©ponse
                    st.success("âœ… RÃ©ponse reÃ§ue!")
                    st.markdown("### RÃ©ponse:")
                    st.markdown(answer)
                    
                    # RafraÃ®chir pour afficher dans l'historique
                    st.rerun()
    
    # Bouton pour effacer l'historique
    if st.session_state['chat_history']:
        if st.button("ğŸ—‘ï¸ Effacer l'historique"):
            st.session_state['chat_history'] = []
            st.rerun()

else:
    st.info("ğŸ‘ˆ Veuillez uploader un document ou une image dans la barre latÃ©rale pour commencer.")

